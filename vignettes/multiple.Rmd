---
title: "Estimating a VLMC from multiple time series"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Estimating a VLMC from multiple time series}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(mixvlmc)
```

A Variable Length Markov Chain model can be estimated from a collection of 
time series rather than from a single one. This vignette showcases `mixvlmc`
support of this type of estimation. 

## VLMC estimation

The representation of a collection of time series is by design minimalistic: 
`mixvlmc` expects a simple `list` of vectors, each of which representing a 
discrete time series. They are assumed to use the same state space (this is 
checked by the functions) and to be *independent*. 

### A simple example

Let us consider the power consumption data set included in the package. In  e.g. 
`vignette("covlmc")`, we fitted a VLMC to at least full week of data considered
as a *single* time series. While this is perfectly valid, it makes also sense to
consider *each day* as an independent time series generated by a single VLMC
operating only at the day level. 

We first build the list of daily time series from a week of data as follows:
```{r}
pc_week_15 <- powerconsumption[powerconsumption$week == 15, ]
elec_week_dts <- cut(pc_week_15$active_power,
  breaks = c(0, 0.4, 2, 8),
  labels = c("low", "typical", "high")
)
elec_daily_dts <- tapply(elec_week_dts,
  pc_week_15$year_day,
  \(x) x,
  simplify = FALSE
)
```

Then the VLMC is estimated using the `multi_vlmc()` function. It has almost
the same interface as the `vlmc()`, excepted that it expects a list of time series
rather than an time series:
```{r}
daily_model <- multi_vlmc(elec_daily_dts)
```
The resulting object is a `multi_vlmc` and a `vlmc` (as well as a `ctx_tree`).
It supports all the expected functions that apply to `vlmc` with minimal 
modifications about positions. For instance, it can be drawn as follows:
```{r}
draw(daily_model)
```
For comparison, the week level model is
```{r}
weekly_model <- vlmc(elec_week_dts)
draw(weekly_model)
```
The models are almost identical (in this particular case).

### Automatic model selection

Automatic model selection via an information criterion is supported for multiple
time series based estimation. This is done with `tune_multi_vlmc()` which implements
a very similar interface as `tune_vlmc()`. For instance, using the data above
```{r}
optimal_daily_model <- tune_multi_vlmc(elec_daily_dts)
optimal_weekly_model <- tune_vlmc(elec_week_dts)
```
Results can be represented graphically as in the simpler case of `tune_vlmc()`:
```{r}
library(ggplot2)
autoplot(optimal_daily_model)
```
The optimal model is extracted from the results using the `as_vlmc()` function:

```{r}
draw(as_vlmc(optimal_daily_model))
```

After model selection, both data sets give the same final model, as shown below:

```{r}
draw(as_vlmc(optimal_weekly_model))
```

This is somewhat expected as the optimal model estimated on the full time series
as a small order. As a consequence, most of the observations are considered in 
the same way in both approaches. 

## Theoretical aspects
### Hypotheses

The estimation strategy of `multi_vlmc()` uses a simple independent and identically
distributed hypothesis: we assume there is fixed VLMC model $\mathcal{M}$ that
generates $P$ independent times series $(x^{(p)}_i)_{1\leq i\leq n_p}$, for 
$1\leq p\leq P$, on the same state space $S$. The length of each time series 
$(n_p)_{1\leq p\leq P}$ is not modelled.  

The context tree of the collection of time series is computed at once, which occurrence
counts aggregated of the collection. This means that asking for a `min_size` of
4 in `multi_vlmc()`, for instance, corresponds to keeping only contexts that 
appear at least 4 times overall: such a context could appear 4 times in a single 
time series, one time in four series, or any other combination. 

The context tree is then processed as if it were the context tree of a single
time series. In particular, conditional probabilities are computed using frequencies 
(maximum likelihood estimation), etc. 
