<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="mixvlmc">
<title>Variable length Markov chains (VLMC) • mixvlmc</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Variable length Markov chains (VLMC)">
<meta property="og:description" content="mixvlmc">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">mixvlmc</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/context-trees.html">Context trees</a>
    <a class="dropdown-item" href="../articles/covlmc.html">Variable Length Markov Chains with Covariates (COVLMC)</a>
    <a class="dropdown-item" href="../articles/sampling.html">Sampling from (CO)VLMC</a>
    <a class="dropdown-item" href="../articles/variable-length-markov-chains.html">Variable length Markov chains (VLMC)</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/fabrice-rossi/mixvlmc/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Variable length Markov chains (VLMC)</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/fabrice-rossi/mixvlmc/blob/HEAD/vignettes/variable-length-markov-chains.Rmd" class="external-link"><code>vignettes/variable-length-markov-chains.Rmd</code></a></small>
      <div class="d-none name"><code>variable-length-markov-chains.Rmd</code></div>
    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/fabrice-rossi/mixvlmc" class="external-link">mixvlmc</a></span><span class="op">)</span></span></code></pre></div>
<p>A <a href="https://en.wikipedia.org/wiki/Markov_chain" class="external-link">Markov
chain</a> is a probabilistic model for time series in which the
probability of the next state depends only on finite memory of previous
states (including the current state). The most common case is the
<em>order one</em> Markov chain, in which the memory is limited to the
current state.</p>
<p>We consider here only Markov chains with finite state spaces.</p>
<div class="section level2">
<h2 id="theoretical-aspects">Theoretical aspects<a class="anchor" aria-label="anchor" href="#theoretical-aspects"></a>
</h2>
<div class="section level3">
<h3 id="high-order-markov-chains">High order Markov chains<a class="anchor" aria-label="anchor" href="#high-order-markov-chains"></a>
</h3>
<p>Let us denote <span class="math inline">\(X_1, X_2, \ldots, X_n,
\ldots\)</span> a sequence of random variables. It is a (stationary)
Markov chain of order <span class="math inline">\(m\)</span> is for all
<span class="math inline">\(n&gt;m\)</span> <span class="math display">\[
\begin{multline}
\mathbb{P}(X_n=x_n|X_{n-1}=x_{n-1}, X_{n-2}=x_{n-2}, \ldots,
X_{1}=x_{1})=\\
\mathbb{P}(X_n=x_n|X_{n-1}=x_{n-1}, X_{n-2}=x_{n-2}, \ldots,
X_{n-m}=x_{n-m}).
\end{multline}
\]</span> To specify such a Markov chain of order <span class="math inline">\(m\)</span>, one needs to describe the conditional
distribution on the right hand side of the previous equation for all
values of the past, i.e. for all contexts (see
<code><a href="../articles/context-trees.html">vignette("context-trees")</a></code>).</p>
<p>For a state space with <span class="math inline">\(k\)</span> states,
we need <span class="math inline">\(k-1\)</span> parameters to specify
completely <span class="math display">\[
\mathbb{P}(X_n=x_n|X_{n-1}=x_{n-1}, X_{n-2}=x_{n-2}, \ldots,
X_{n-m}=x_{n-m})
\]</span> for all values of <span class="math inline">\(x_n\)</span> and
for <em>a single</em> context <span class="math inline">\((x_{n-1},
x_{n-2}, \ldots, x_{n-m})\)</span>.<br>
There are <span class="math inline">\(k^{m-1}\)</span> such contexts and
thus we need a total of <span class="math inline">\((k-1)k^{m-1}\)</span> parameters to specify
completely a Markov chain of order <span class="math inline">\(m\)</span> on a state space with <span class="math inline">\(k\)</span> states.</p>
<p>Unfortunately, the exponential growth with respect to the order makes
high order Markov chain unrealistic on a statistical point of view: the
number of parameters to estimate grows too quickly compared to the
typical length of a time series.</p>
<p>If we consider a <a href="https://en.wikipedia.org/wiki/Gene" class="external-link">gene</a> as a sequence of
(pair of) bases, we have a state space with <span class="math inline">\(k=4\)</span> states. The mean protein-coding
length for <a href="https://en.wikipedia.org/wiki/Human_genome" class="external-link">humans</a> is roughly
66,000 (pairs of) bases. The following table shows the growth of the
parameter number for <span class="math inline">\(k=4\)</span> with the
order of a Markov chain. There are already way too many parameter with
<span class="math inline">\(m=7\)</span> for a proper estimation based
on a single gene of an average length. Even the longest genes would be
insufficient for <span class="math inline">\(m=10\)</span>.</p>
<pre><code><span><span class="co">#&gt;     m parameters</span></span>
<span><span class="co">#&gt; 1   1         12</span></span>
<span><span class="co">#&gt; 2   2         48</span></span>
<span><span class="co">#&gt; 3   3        192</span></span>
<span><span class="co">#&gt; 4   4        768</span></span>
<span><span class="co">#&gt; 5   5       3072</span></span>
<span><span class="co">#&gt; 6   6      12288</span></span>
<span><span class="co">#&gt; 7   7      49152</span></span>
<span><span class="co">#&gt; 8   8     196608</span></span>
<span><span class="co">#&gt; 9   9     786432</span></span>
<span><span class="co">#&gt; 10 10    3145728</span></span></code></pre>
</div>
<div class="section level3">
<h3 id="sparse-models">Sparse models<a class="anchor" aria-label="anchor" href="#sparse-models"></a>
</h3>
<p>While higher order Markov chains would be very useful to capture long
memory in time series, the exponential growth of their parameter space
is incompatible with this goal. Variable length Markov chains provide a
compromise between the controlled number of parameters of low order
Markov chains and the long memory of high order ones. The key idea is to
consider that the dependency order can depend on the context itself.</p>
<p>Let us consider a simple example with a binary valued time series
(<span class="math inline">\(k=2\)</span>) and a Markov chain of order
3. We need to specify for instance the probability of <span class="math inline">\(X_n=1\)</span> given the eight possible contexts,
from <span class="math inline">\((0, 0, 0)\)</span> to <span class="math inline">\((1, 1, 1)\)</span>. A possible choice is</p>
<pre><code><span><span class="co">#&gt;   Probablity n-1 n-2 n-3</span></span>
<span><span class="co">#&gt; 1        0.1   0   0   0</span></span>
<span><span class="co">#&gt; 2        0.2   1   0   0</span></span>
<span><span class="co">#&gt; 3        0.1   0   1   0</span></span>
<span><span class="co">#&gt; 4        0.3   1   1   0</span></span>
<span><span class="co">#&gt; 5        0.1   0   0   1</span></span>
<span><span class="co">#&gt; 6        0.4   1   0   1</span></span>
<span><span class="co">#&gt; 7        0.1   0   1   1</span></span>
<span><span class="co">#&gt; 8        0.3   1   1   1</span></span></code></pre>
<p>In this table, several contexts share the same conditional
probability distribution. For instance <span class="math display">\[
\mathbb{P}(X_n=1|X_{n-1}=0,
X_{n-2}=0,X_{n-3}=0)=\mathbb{P}(X_n=1|X_{n-1}=0, X_{n-2}=1,X_{n-3}=0).
\]</span></p>
<p>In fact, a careful look at the table shows that <span class="math display">\[
\begin{align*}
\mathbb{P}(X_n=1|X_{n-1}=0, X_{n-2}=a, X_{n-3}=b)&amp;=0.1&amp;\forall
a, \forall b,\\
\mathbb{P}(X_n=1|X_{n-1}=1, X_{n-2}=1, X_{n-3}=c)&amp;=0.3&amp;\forall
c,\\
\mathbb{P}(X_n=1|X_{n-1}=1, X_{n-2}=0, X_{n-3}=0)&amp;=0.2,&amp;\\
\mathbb{P}(X_n=1|X_{n-1}=1, X_{n-2}=0, X_{n-3}=1)&amp;=0.4,
\end{align*}
\]</span> and thus the Markov chain can be described by only 4
probability distributions rather than 8. The corresponding contexts
are:</p>
<ul>
<li>
<span class="math inline">\((0)\)</span> : short memory only when
the last state is 0</li>
<li>
<span class="math inline">\((1, 1)\)</span> : second order memory
when the two last states are 1</li>
<li>
<span class="math inline">\((1, 0, 0)\)</span> and <span class="math inline">\((1, 0, 1)\)</span> : full third order memory</li>
</ul>
<p>This third order Markov chain is parsimonious in the sense that it
can be described by the four contexts and their associated probability
distributions rather than by the full collection needed for an arbitrary
third order Markov chain.</p>
</div>
<div class="section level3">
<h3 id="variable-length-markov-chain">Variable length Markov chain<a class="anchor" aria-label="anchor" href="#variable-length-markov-chain"></a>
</h3>
<p>A variable length Markov chain (VLMC) is a sparse high order Markov
chain. Let us denote <span class="math inline">\(X_1, X_2, \ldots, X_n,
\ldots\)</span> a sequence of random variables taking values in the
finite state space <span class="math inline">\(S\)</span>. The sequence
is a VLMC if there is a maximal order <span class="math inline">\(l_{\max}\)</span> and a function <span class="math inline">\(l\)</span> from <span class="math inline">\(S^{l_{\max}}\)</span> to <span class="math inline">\(\{0,\ldots,l_{\max}\}\)</span> such that for all
<span class="math inline">\(n&gt;l_{\max}\)</span> <span class="math display">\[
\begin{multline}
\mathbb{P}(X_n=x_n|X_{n-1}=x_{n-1}, X_{n-2}=x_{n-2}, \ldots,
X_{1}=x_{1})=\\
\mathbb{P}(X_n=x_n|X_{n-1}=x_{n-1}, X_{n-2}=x_{n-2}, \ldots,
X_{n-l(x_{n-1},\ldots,x_{n-l_{\max}})}=x_{n-l(x_{n-1},\ldots,x_{n-l_{\max}})}).
\end{multline}
\]</span> In other words, the memory length (the order) is
<em>variable</em> and given by <span class="math inline">\(l(x_{n-1},\ldots,x_{n-l_{\max}})\)</span>.</p>
<p>The memory length function generates a <em>context</em> function
<span class="math inline">\(c\)</span> which keeps in the past the part
needed to obtain the conditional distribution: <span class="math inline">\(c\)</span> is a function from <span class="math inline">\(S^{l_{\max}}\)</span> to <span class="math inline">\(\bigcup_{k=0}^{l_{\max}}S^k\)</span> given by:
<span class="math display">\[
c(x_1, x_2, \ldots, x_{l_{\max}})=(x_1,\ldots,x_{l(x_1, x_2, \ldots,
x_{l_{\max}})})
\]</span> The image by <span class="math inline">\(c\)</span> of <span class="math inline">\(S^{l_{\max}}\)</span> is the set of contexts of
the VLMC which is entirely specified by <span class="math inline">\(l\)</span> and one conditional distribution by
unique context.</p>
<p>In the above example, <span class="math inline">\(l_{\max}=3\)</span>
and <span class="math inline">\(l\)</span> is defined from <span class="math inline">\(\{0, 1\}^3\)</span> to <span class="math inline">\(\{0, 1, 2, 3\}\)</span> by <span class="math display">\[
\begin{align*}
l(0, a, b)&amp;=1&amp;\forall a, \forall b,\\
l(1, 1, c)&amp;=2&amp;\forall c,\\
l(1, 0, 0)&amp;=3,&amp;\\
l(1, 0, 1)&amp;=3.&amp;\\
\end{align*}
\]</span></p>
</div>
<div class="section level3">
<h3 id="vlmc-estimation">VLMC estimation<a class="anchor" aria-label="anchor" href="#vlmc-estimation"></a>
</h3>
<p>If we assume that an observed time series has been generated by a
VLMC, we can try and estimate from it the <span class="math inline">\(l\)</span> function and the corresponding
conditional probabilities. This is a non-parametric estimation problem
as <span class="math inline">\(l_{\max}\)</span> is unknown. A natural
way to carry on the estimation is to use some form of penalized
likelihood approach.</p>
<p>This is done by first extracting from the time series its context
tree (see <code><a href="../articles/context-trees.html">vignette("context-trees")</a></code>), a sparse
representation of all the sub-sequences (i.e. contexts) that appear at
least a few times in the time series. Each unique sub-sequence/context
is followed by a state in the time series: this is used to estimate the
conditional probabilities (from frequencies). Finally a pruning
algorithm is applied to balance the complexity of the tree with its
likelihood (given the time series).</p>
</div>
</div>
<div class="section level2">
<h2 id="vlmc-in-practice">VLMC in practice<a class="anchor" aria-label="anchor" href="#vlmc-in-practice"></a>
</h2>
<div class="section level3">
<h3 id="estimation">Estimation<a class="anchor" aria-label="anchor" href="#estimation"></a>
</h3>
<p>VLMC estimation is provided by the <code><a href="../reference/vlmc.html">vlmc()</a></code> function as in
the following example.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">0</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0L</span>, <span class="fl">1L</span>, <span class="fl">2L</span><span class="op">)</span>, <span class="fl">200</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/vlmc.html">vlmc</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="va">model</span></span>
<span><span class="co">#&gt; VLMC context tree on 0, 1, 2 </span></span>
<span><span class="co">#&gt;  cutoff: 2.996 (quantile: 0.05)</span></span>
<span><span class="co">#&gt;  Number of contexts: 4 </span></span>
<span><span class="co">#&gt;  Maximum context length: 3</span></span></code></pre></div>
<p>The estimation process is controlled by three parameters:</p>
<ul>
<li>
<code>max_depth</code>: the largest order/memory considered for the
VLMC (defaults to 100). This parameter is essentially a computational
burden control parameter and should be increased to a larger value if
the final model has contexts that reach the maximum value (this is done
automatically in <code><a href="../reference/tune_vlmc.html">tune_vlmc()</a></code>);</li>
<li>
<code>min_size</code>: the minimum number of occurrences of a
context in the time series for it to be included in the context tree
during the first phase of the algorithm. The default 2 value is very
conservative. Larger values will produce simpler trees;</li>
<li>
<code>alpha</code>/<code>cutoff</code>: this is the main complexity
control parameter, which can be expressed in two different scales.
<code>cutoff</code> is expressed in the native Kullback-Liebler
divergence scale used to assess the difference between conditional
probability distributions given different contexts. <code>alpha</code>
is expressed in a more convenient universal scale based on the quantiles
of the Chi-Squared distribution that appears when the pruning criterion
is interpreted as a likelihood ratio test (the default is
<code>alpha=0.05</code>).</li>
</ul>
<p>It is recommended to use the default value for <code>min_size</code>,
to increase <code>max_depth</code> only in case of “overflow” (i.e. when
the maximum context length reaches <code>max_depth</code>) and to use
only <code>alpha</code> to control the complexity of the VLMC,
preferably automatically with <code><a href="../reference/tune_vlmc.html">tune_vlmc()</a></code>. An important
point to note is that a <em>higher</em> value of <code>alpha</code>
leads to a more complex model as does a <em>lower</em> value of
<code>cutoff</code>.</p>
<p>Based on theoretical results, the order of magnitude of
<code>cutoff</code> should be in <span class="math inline">\(K \log
n\)</span> (for <span class="math inline">\(n\)</span> observations),
where <span class="math inline">\(K\)</span> depends on the type of
convergence analysis conducted. For instance a BIC inspired value for
<span class="math inline">\(K\)</span> is <span class="math inline">\((|S|-1)/2\)</span> for a state space <span class="math inline">\(S\)</span> (of size <span class="math inline">\(|S|\)</span>). In the above example, we get:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model_theo</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/vlmc.html">vlmc</a></span><span class="op">(</span><span class="va">x</span>, cutoff <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">model_theo</span></span>
<span><span class="co">#&gt; VLMC context tree on 0, 1, 2 </span></span>
<span><span class="co">#&gt;  cutoff: 5.298 (quantile: 0.005)</span></span>
<span><span class="co">#&gt;  Number of contexts: 0 </span></span>
<span><span class="co">#&gt;  Maximum context length: 0</span></span></code></pre></div>
<p>The result is a memory less model, as expected based on the way
<code>x</code> was generated. In this situation, the chosen value of
<code>cutoff</code> leads to the optimal model, but this is not always
the case as this choice is only informed by asymptotic analysis.</p>
</div>
<div class="section level3">
<h3 id="model-choice">Model choice<a class="anchor" aria-label="anchor" href="#model-choice"></a>
</h3>
<p>In practice, it is recommended to start with a conservative value of
<code>cutoff</code> (or <code>alpha</code>) and to use a penalized
criterion to find the best model in a way that balances likelihood and
complexity. A conservative value of <code>cutoff</code> is a small one,
while <code>alpha</code> should be high to be conservative. A possible
choice is to use the BIC inspired <code>cutoff</code> divided by a fixed
value, for instance <span class="math inline">\(\frac{1}{4}(|S|-1)\log
n\)</span>.</p>
<p>Once a “large” model has been obtained, two functions can be used to
generate the collection of simpler models that would have been obtained
by using larger values of <code>cutoff</code>. The function
<code><a href="../reference/cutoff.html">cutoff()</a></code> returns a list of values (in <code>alpha</code>
scale by default) that are guaranteed to contain all values that can
generate simpler models that the reference one. For instance in the
following code</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model_large</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/vlmc.html">vlmc</a></span><span class="op">(</span><span class="va">x</span>, cutoff <span class="op">=</span> <span class="fl">0.5</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">model_large</span></span>
<span><span class="co">#&gt; VLMC context tree on 0, 1, 2 </span></span>
<span><span class="co">#&gt;  cutoff: 2.649 (quantile: 0.0707106781186548)</span></span>
<span><span class="co">#&gt;  Number of contexts: 6 </span></span>
<span><span class="co">#&gt;  Maximum context length: 3</span></span>
<span><span class="va">model_cutoff</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/cutoff.html">cutoff</a></span><span class="op">(</span><span class="va">model_large</span>, mode <span class="op">=</span> <span class="st">"native"</span><span class="op">)</span></span>
<span><span class="va">model_cutoff</span></span>
<span><span class="co">#&gt; [1] 3.177898 3.784875</span></span></code></pre></div>
<p>we first adjust a “complex” model using `<code>cutoff=`2.65</code>
and find then that 2 other values can be used to build simpler models,
using <code><a href="../reference/prune.html">prune()</a></code> as follows:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model_medium</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/prune.html">prune</a></span><span class="op">(</span><span class="va">model_large</span>, cutoff <span class="op">=</span> <span class="va">model_cutoff</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="va">model_medium</span></span>
<span><span class="co">#&gt; VLMC context tree on 0, 1, 2 </span></span>
<span><span class="co">#&gt;  cutoff: 3.178 (quantile: 0.0416731573600126)</span></span>
<span><span class="co">#&gt;  Number of contexts: 4 </span></span>
<span><span class="co">#&gt;  Maximum context length: 3</span></span></code></pre></div>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model_small</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/prune.html">prune</a></span><span class="op">(</span><span class="va">model_large</span>, cutoff <span class="op">=</span> <span class="va">model_cutoff</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="va">model_small</span></span>
<span><span class="co">#&gt; VLMC context tree on 0, 1, 2 </span></span>
<span><span class="co">#&gt;  cutoff: 3.785 (quantile: 0.0227117061190262)</span></span>
<span><span class="co">#&gt;  Number of contexts: 0 </span></span>
<span><span class="co">#&gt;  Maximum context length: 0</span></span></code></pre></div>
<p>The final model <code>model_small</code> is again the memory less
model.</p>
</div>
<div class="section level3">
<h3 id="automatic-model-choice">Automatic model choice<a class="anchor" aria-label="anchor" href="#automatic-model-choice"></a>
</h3>
<p>The pair <code><a href="../reference/cutoff.html">cutoff()</a></code>/<code><a href="../reference/prune.html">prune()</a></code> can be used to
implement advanced model selection techniques, for instance based on the
quality of the predictions of the model on a hold-out example. For a
more standard use, the <code><a href="../reference/tune_vlmc.html">tune_vlmc()</a></code> provides a fully
automated solution, including the choice of conservative values of the
initial cut off and of a large enough <code>max_depth</code>, as
demonstrated below:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model_tune</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/tune_vlmc.html">tune_vlmc</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="va">model_opt</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/as_vlmc.html">as_vlmc</a></span><span class="op">(</span><span class="va">model_tune</span><span class="op">)</span></span>
<span><span class="va">model_opt</span></span>
<span><span class="co">#&gt; VLMC context tree on 0, 1, 2 </span></span>
<span><span class="co">#&gt;  cutoff: 3.785 (quantile: 0.0227117061190262)</span></span>
<span><span class="co">#&gt;  Number of contexts: 0 </span></span>
<span><span class="co">#&gt;  Maximum context length: 0</span></span></code></pre></div>
<p>We obtain directly an optimal model according to the BIC
criterion.</p>
</div>
<div class="section level3">
<h3 id="diagnostics">Diagnostics<a class="anchor" aria-label="anchor" href="#diagnostics"></a>
</h3>
<p>The package provides numerous ways to analyse a VLMC. Basic functions
include</p>
<ul>
<li>
<code><a href="../reference/states.html">states()</a></code> returns the state space of the model;</li>
<li>
<code><a href="../reference/depth.html">depth()</a></code> returns the length of the longest context in
the model;</li>
<li>
<code><a href="../reference/context_number.html">context_number()</a></code> returns the number of contexts in the
model.</li>
</ul>
<p>For instance, the large model obtained above has the following
characteristics:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/states.html">states</a></span><span class="op">(</span><span class="va">model_large</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0 1 2</span></span>
<span><span class="fu"><a href="../reference/depth.html">depth</a></span><span class="op">(</span><span class="va">model_large</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 3</span></span>
<span><span class="fu"><a href="../reference/context_number.html">context_number</a></span><span class="op">(</span><span class="va">model_large</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 6</span></span></code></pre></div>
<p>VLMC objects support classical statistical functions such as:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/logLik.html" class="external-link">logLik</a></span><span class="op">(</span><span class="va">model_large</span><span class="op">)</span></span>
<span><span class="co">#&gt; 'log Lik.' -206.1223 (df=12)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/AIC.html" class="external-link">AIC</a></span><span class="op">(</span><span class="va">model_large</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 436.2446</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/AIC.html" class="external-link">BIC</a></span><span class="op">(</span><span class="va">model_large</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 475.8244</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="contexts">Contexts<a class="anchor" aria-label="anchor" href="#contexts"></a>
</h3>
<p>The model can be explored in details by drawing its context tree (see
<code><a href="../articles/context-trees.html">vignette("context-trees")</a></code> for details) as follows:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/draw.html">draw</a></span><span class="op">(</span><span class="va">model_large</span><span class="op">)</span></span>
<span><span class="co">#&gt; * (0.325, 0.345, 0.33)</span></span>
<span><span class="co">#&gt; '-- 1 (0.3043, 0.4203, 0.2754)</span></span>
<span><span class="co">#&gt;     +-- 1 (0.2069, 0.4828, 0.3103)</span></span>
<span><span class="co">#&gt;     |   '-- 0 (0.2222, 0.7778, 0)</span></span>
<span><span class="co">#&gt;     '-- 2 (0.3, 0.3, 0.4)</span></span>
<span><span class="co">#&gt;         '-- 2 (0, 0.375, 0.625)</span></span></code></pre></div>
<p>To explore the contexts in a programmatic way, one should rely on the
<code><a href="../reference/contexts.html">contexts()</a></code> function. VLMC contexts have additional
characteristics compared to context trees. In particular, the
<code><a href="../reference/contexts.html">contexts()</a></code> function can report the log likelihood ratio
associated to each context as follows (compare to <code><a href="../reference/cutoff.html">cutoff()</a></code>
above):</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/contexts.html">contexts</a></span><span class="op">(</span><span class="va">model_large</span>, cutoff <span class="op">=</span> <span class="st">"native"</span><span class="op">)</span></span>
<span><span class="co">#&gt;   context    cutoff</span></span>
<span><span class="co">#&gt; 1 1, 1, 0 3.4813864</span></span>
<span><span class="co">#&gt; 2    1, 1 0.7006631</span></span>
<span><span class="co">#&gt; 3 1, 2, 2 2.9008662</span></span>
<span><span class="co">#&gt; 4    1, 2 0.8777091</span></span>
<span><span class="co">#&gt; 5       1 0.9067789</span></span>
<span><span class="co">#&gt; 6         0.0000000</span></span></code></pre></div>
<p>Notice that by default <code><a href="../reference/contexts.html">contexts()</a></code> uses the reverse
representation of contexts, but they can be returned in the natural time
sequence using <code>reverse=FALSE</code>, as in</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/contexts.html">contexts</a></span><span class="op">(</span><span class="va">model_large</span>, cutoff <span class="op">=</span> <span class="st">"quantile"</span>, reverse <span class="op">=</span> <span class="cn">FALSE</span>, frequency <span class="op">=</span> <span class="st">"detailed"</span><span class="op">)</span></span>
<span><span class="co">#&gt;   context freq  0  1  2     cutoff</span></span>
<span><span class="co">#&gt; 1 0, 1, 1    9  2  7  0 0.03076473</span></span>
<span><span class="co">#&gt; 2    1, 1   29  6 14  9 0.49625611</span></span>
<span><span class="co">#&gt; 3 2, 2, 1    8  0  3  5 0.05497558</span></span>
<span><span class="co">#&gt; 4    2, 1   20  6  6  8 0.41573421</span></span>
<span><span class="co">#&gt; 5       1   69 21 29 19 0.40382287</span></span>
<span><span class="co">#&gt; 6          200 65 69 66 1.00000000</span></span></code></pre></div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Fabrice Rossi.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
