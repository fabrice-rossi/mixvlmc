<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="mixvlmc">
<title>Variable Length Markov Chains with Covariates (COVLMC) • mixvlmc</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Variable Length Markov Chains with Covariates (COVLMC)">
<meta property="og:description" content="mixvlmc">
<meta name="robots" content="noindex">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">mixvlmc</a>

    <small class="nav-text text-danger me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="In-development version">0.1.1.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <h6 class="dropdown-header" data-toc-skip>Getting started</h6>
    <a class="dropdown-item" href="../articles/context-trees.html">Context trees</a>
    <a class="dropdown-item" href="../articles/variable-length-markov-chains.html">Variable length Markov chains (VLMC)</a>
    <a class="dropdown-item" href="../articles/covlmc.html">Variable Length Markov Chains with Covariates (COVLMC)</a>
    <div class="dropdown-divider"></div>
    <h6 class="dropdown-header" data-toc-skip>Advanced topics</h6>
    <a class="dropdown-item" href="../articles/likelihood.html">Likelihood calculation</a>
    <a class="dropdown-item" href="../articles/prediction.html">Predicting with (CO)VLMC</a>
    <a class="dropdown-item" href="../articles/sampling.html">Sampling from (CO)VLMC</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-news">News</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-news">
    <h6 class="dropdown-header" data-toc-skip>Releases</h6>
    <a class="external-link dropdown-item" href="https://fabrice-rossi.github.io/blog/posts/mixvlmc-0-1.html">mixvlmc 0.1.1</a>
    <div class="dropdown-divider"></div>
    <a class="dropdown-item" href="../news/index.html">Changelog</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/fabrice-rossi/mixvlmc/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Variable Length Markov Chains with Covariates (COVLMC)</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/fabrice-rossi/mixvlmc/blob/HEAD/vignettes/covlmc.Rmd" class="external-link"><code>vignettes/covlmc.Rmd</code></a></small>
      <div class="d-none name"><code>covlmc.Rmd</code></div>
    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/fabrice-rossi/mixvlmc" class="external-link">mixvlmc</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org" class="external-link">ggplot2</a></span><span class="op">)</span></span></code></pre></div>
<div class="section level2">
<h2 id="limitations-of-variable-length-markov-chains">Limitations of Variable Length Markov Chains<a class="anchor" aria-label="anchor" href="#limitations-of-variable-length-markov-chains"></a>
</h2>
<p>Variable Length Markov Chains (VLMC) are very useful to capture
complex structures in discrete time series as they can mix short memory
with long memory in a contextual way, leading to sparse models.</p>
<p>However, they cannot capture the influence of exogenous variables on
the behaviour of a time series. As a consequence, a VLMC adjusted on
sequences influenced by covariates could fail to capture interesting
patterns.</p>
<div class="section level3">
<h3 id="a-typical-example">A typical example<a class="anchor" aria-label="anchor" href="#a-typical-example"></a>
</h3>
<p>Let us focus again on the electrical usage data set used in the
package introduction, using the following two weeks of data:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pc_week_15_16</span> <span class="op">&lt;-</span> <span class="va">powerconsumption</span><span class="op">[</span><span class="va">powerconsumption</span><span class="op">$</span><span class="va">week</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">15</span>, <span class="fl">16</span><span class="op">)</span>, <span class="op">]</span></span>
<span><span class="va">elec</span> <span class="op">&lt;-</span> <span class="va">pc_week_15_16</span><span class="op">$</span><span class="va">active_power</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">pc_week_15_16</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">date_time</span>, y <span class="op">=</span> <span class="va">active_power</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html" class="external-link">geom_line</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">xlab</a></span><span class="op">(</span><span class="st">"Date"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">ylab</a></span><span class="op">(</span><span class="st">"Activer power (kW)"</span><span class="op">)</span></span></code></pre></div>
<p><img src="covlmc_files/figure-html/active_power_week_15_16-1.png" width="672" style="display: block; margin: auto;"></p>
<p>We build again a discrete time series using the following
thresholds:</p>
<ul>
<li>low active power at night (typically below 0.4 kW);</li>
<li>standard use between 0.4 and 2 kW;</li>
<li>peak use above 2 kW.</li>
</ul>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">elec_dts</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cut.html" class="external-link">cut</a></span><span class="op">(</span><span class="va">elec</span>, breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.4</span>, <span class="fl">2</span>, <span class="fl">8</span><span class="op">)</span>, labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"low"</span>, <span class="st">"typical"</span>, <span class="st">"high"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>Adjusting a VLMC to this sequence gives the following model (using
BIC for model selection):</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">elec_vlmc_tune</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/tune_vlmc.html">tune_vlmc</a></span><span class="op">(</span><span class="va">elec_dts</span><span class="op">)</span></span>
<span><span class="va">best_elec_vlmc</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/as_vlmc.html">as_vlmc</a></span><span class="op">(</span><span class="va">elec_vlmc_tune</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/draw.html">draw</a></span><span class="op">(</span><span class="va">best_elec_vlmc</span><span class="op">)</span></span>
<span><span class="co">#&gt; * (0.3269, 0.4841, 0.189)</span></span>
<span><span class="co">#&gt; +-- low (0.8088, 0.1821, 0.009105)</span></span>
<span><span class="co">#&gt; '-- typical (0.1292, 0.8041, 0.06667)</span></span>
<span><span class="co">#&gt; |   +-- low (0.3667, 0.5833, 0.05)</span></span>
<span><span class="co">#&gt; |   '-- typical (0.1022, 0.8365, 0.0613)</span></span>
<span><span class="co">#&gt; |       '-- low (0.4058, 0.5507, 0.04348)</span></span>
<span><span class="co">#&gt; '-- high (0, 0.1864, 0.8136)</span></span></code></pre></div>
<p>Considering the apparent regularity of the time series, one may
wonder whether this model is really capturing the dynamics of power
electricity consumption. In particular the longest memory of 3 time
steps, i.e., 30 minutes, may seem a bit short compared to the somewhat
long periods of stability.</p>
</div>
</div>
<div class="section level2">
<h2 id="theoretical-aspects">Theoretical aspects<a class="anchor" aria-label="anchor" href="#theoretical-aspects"></a>
</h2>
<p>VLMC with covariates have been introduced in <a href="https://doi.org/10.1111/jtsa.12615" class="external-link">Variable length Markov chain
with exogenous covariates</a>. The core idea is to enable the
conditional probabilities of the next state given the context to depend
on exogenous covariates.</p>
<div class="section level3">
<h3 id="variable-memory">Variable memory<a class="anchor" aria-label="anchor" href="#variable-memory"></a>
</h3>
<p>A COVLMC models a pair of sequences. The main sequence is denoted
<span class="math inline">\(\mathbf{X}=X_1, X_2, \ldots, X_n,
\ldots\)</span>. The random variables take values in a finite state
space <span class="math inline">\(S\)</span> exactly as in a standard
VLMC. We have <em>in addition</em> another sequence of random variables
<span class="math inline">\(\mathbf{Y}=Y_1, Y_2, \ldots, Y_n,
\ldots\)</span> which take values in <span class="math inline">\(\mathbb{R}^p\)</span>. This latter assumption
<span class="math inline">\(Y_l\in \mathbb{R}^p\)</span> is can be
relaxed to more general spaces.</p>
<p>A COVLMC puts restriction on the conditional probabilities of <span class="math inline">\(X_n\)</span> given the past of <em>both</em>
sequences. To simplify the presentation, we denote <span class="math inline">\(X^k_l\)</span> the sequence of random variables
<span class="math display">\[
X^k_m=(X_k, X_{k-1}, \ldots, X_m),
\]</span> and we use similar notations for the values taken by the
variables <span class="math inline">\(x^k_m\)</span>, as well as for
<span class="math inline">\(Y^k_m\)</span> and <span class="math inline">\(y^k_m\)</span>. We use here the traditional
reverser ordering in which <span class="math inline">\(X_k\)</span> is
the more recent variable and <span class="math inline">\(X_m\)</span>
the oldest.</p>
<p>A pair of sequences <span class="math inline">\(\mathbf{X}\)</span>
and <span class="math inline">\(\mathbf{Y}\)</span> is a COVLMC if there
is a maximal order <span class="math inline">\(l_{\max}\)</span> and a
function <span class="math inline">\(l\)</span> from <span class="math inline">\(S^{l_{\max}}\)</span> to <span class="math inline">\(\{0,\ldots,l_{\max}\}\)</span> such that for all
<span class="math inline">\(n&gt;l_{\max}\)</span> <span class="math display">\[
\begin{multline}
\mathbb{P}(X_n=x_n\mid X^{n-1}_1=x^{n-1}_1, Y^{n-1}_1=y^{n-1}_1)=\\
\mathbb{P}\left(X_n=x_n\mid
X^{n-1}_{n-l\left(x^{n-1}_{n-l_{\max}}\right)}=x^{n-1}_{n-l\left(x^{n-1}_{n-l_{\max}}\right)},
Y^{n-1}_{n-l\left(x^{n-1}_{n-l_{\max}}\right)}=y^{n-1}_{n-l\left(x^{n-1}_{n-l_{\max}}\right)}\right).
\end{multline}
\]</span> As in VLMC, the <span class="math inline">\(\mathbf{X}\)</span> process has a finite and
variable memory, but this memory applies to both <span class="math inline">\(\mathbf{X}\)</span> and <span class="math inline">\(\mathbf{Y}\)</span>. Notice that the memory order
depends only on <span class="math inline">\(\mathbf{X}\)</span> and that
no assumptions are made on the temporal behaviour of <span class="math inline">\(\mathbf{Y}\)</span>. Thus a COVLMC on <span class="math inline">\(\mathbf{X}\)</span> and <span class="math inline">\(\mathbf{Y}\)</span> is not a VLMC on the pair
<span class="math inline">\((\mathbf{X}, \mathbf{Y})\)</span> (which can
make sense if <span class="math inline">\(\mathbf{Y}\)</span> is
discrete).</p>
<p>As for VLMC, the memory length function generates a <em>context</em>
function <span class="math inline">\(c\)</span> which keeps in the past
the part needed to obtain the conditional distribution: <span class="math inline">\(c\)</span> is a function from <span class="math inline">\(S^{l_{\max}}\)</span> to <span class="math inline">\(\bigcup_{k=0}^{l_{\max}}S^k\)</span> given by
<span class="math display">\[
c(x^{n-1}_{n-l_{\max}})=x^{n-1}_{n-l\left(x^{n-1}_{n-l_{\max}}\right)}
\]</span> The image by <span class="math inline">\(c\)</span> of <span class="math inline">\(S^{l_{\max}}\)</span> is the set of contexts of
the COVLMC which is entirely specified by <span class="math inline">\(l\)</span> and one conditional distribution by
unique context.</p>
<p>As the notations are somewhat opaque at first, we can illustrate the
definition with a simple example. We consider a binary sequence (values
in <span class="math inline">\(S=\{0, 1\}\)</span>) and a single
numerical covariate <span class="math inline">\(Y_t\in\mathbb{R}\)</span>. As in the theoretical
example in <code><a href="../articles/variable-length-markov-chains.html">vignette("variable-length-markov-chains")</a></code> we
assume that <span class="math inline">\(l_{\max}=3\)</span> and that
<span class="math inline">\(l\)</span> is given by <span class="math display">\[
\begin{align*}
l(0, a, b)&amp;=1&amp;\forall a, \forall b,\\
l(1, 1, c)&amp;=2&amp;\forall c,\\
l(1, 0, 0)&amp;=3,&amp;\\
l(1, 0, 1)&amp;=3.&amp;\\
\end{align*}
\]</span> In practice the COVLMC is therefore fully described by
specifying the following probabilities: <span class="math display">\[
\begin{align*}
\mathbb{P}(X_t=1\mid&amp; X_{t-1}=0, Y_{t-1}=y_{t-1})\\
\mathbb{P}(X_t=1\mid&amp; X_{t-1}=1, X_{t-2}=1, Y_{t-1}=y_{t-1},
Y_{t-2}=y_{t-2})\\
\mathbb{P}(X_t=1\mid&amp; X_{t-1}=1, X_{t-2}=0, X_{t-3}=0,
Y_{t-1}=y_{t-1}, Y_{t-2}=y_{t-2}, Y_{t-3}=y_{t-3})\\
\mathbb{P}(X_t=1\mid&amp; X_{t-1}=1, X_{t-2}=0, X_{t-3}=1,
Y_{t-1}=y_{t-1}, Y_{t-2}=y_{t-2}, Y_{t-3}=y_{t-3})
\end{align*}
\]</span></p>
</div>
<div class="section level3">
<h3 id="conditional-distributions">Conditional distributions<a class="anchor" aria-label="anchor" href="#conditional-distributions"></a>
</h3>
<p>The main difficulty induced by COVLMC compared to VLMC is the
specification of the conditional distributions. Indeed the conditional
distributions depend on <span class="math inline">\(\mathbf{Y}\)</span>
and cannot simply be given by a table. For instance, in the example
above, we need to specify, among others, <span class="math inline">\(\mathbb{P}(X_t=1\mid X_{t-1}=0,
Y_{t_1}=y_{t-1})\)</span>, for each all values of <span class="math inline">\(y_{t-1}\in \mathbb{R}\)</span> (in <span class="math inline">\(\mathbb{R}^p\)</span> in the general case).</p>
<p>A natural choice in this particular example is to use a logistic
model, i.e. to assume <span class="math display">\[
\mathbb{P}(X_t=1\mid X_{t-1}=0,
Y_{t_1}=y_{t-1})=g(\alpha^0+y_{t-1}\beta_1^0),
\]</span> with <span class="math inline">\(g(t)=\frac{1}{1+\exp(-t)}\)</span> is the logistic
function. The superscript on <span class="math inline">\(\alpha^0\)</span> and <span class="math inline">\(\beta^0_1\)</span> refer to the context, here
<span class="math inline">\(0\)</span>, while the subscript on <span class="math inline">\(\beta^0_1\)</span> refers to the time delay (here
<span class="math inline">\(1\)</span>). By extension, we have for
example <span class="math display">\[
\begin{multline*}
\mathbb{P}(X_t=1\mid X_{t-1}=1, X_{t-2}=1, Y_{t_1}=y_{t-1},
Y_{t_2}=y_{t-2})=\\
g\left(\alpha^{1,1}+y_{t-1}\beta^{1,1}_1+y_{t-2}\beta^{1,1}_2\right).
\end{multline*}
\]</span></p>
<p>More generally, the probability distribution associated to a context
could be given by any function that maps the values of the covariates to
a distribution on <span class="math inline">\(S\)</span>, the state
space. Following the original <a href="https://doi.org/10.1111/jtsa.12615" class="external-link">paper</a>,
<code>mixvlmc</code> uses multinomial logistic regression as implemented
by <code><a href="https://rdrr.io/pkg/VGAM/man/vglm.html" class="external-link">VGAM::vglm()</a></code> or <code><a href="https://rdrr.io/pkg/nnet/man/multinom.html" class="external-link">nnet::multinom()</a></code>, or a
logistic regression provided by <code><a href="https://rdrr.io/r/stats/glm.html" class="external-link">stats::glm()</a></code> for state
spaces with only 2 states. This has several advantages over a more
general solution:</p>
<ol style="list-style-type: decimal">
<li>during the estimation phase, one probability distribution is
estimated for each relevant context: this could induce a large
computational burden for more complex models than multinomial logistic
ones;</li>
<li>having a simple model enables to fit contexts with limited number of
occurrences which is important to allow searching for long term
dependencies;</li>
<li>logistic models with different memory order are easy to compare
using a likelihood-ratio test.</li>
</ol>
<p>The last point is used in <code>mixvlmc</code> (as in the original
paper) to simplify local models with respect to the covariates. For a
context of length <span class="math inline">\(l\)</span>, the
probability distribution is assumed to depend on the <span class="math inline">\(l\)</span> past values of <span class="math inline">\(\mathbf{Y}\)</span> but in practice we allow a
dependency to only <span class="math inline">\(k&lt;l\)</span> past
values. For instance, we could have <span class="math display">\[
\mathbb{P}(X_t=1\mid X_{t-1}=1, X_{t-2}=1, Y_{t_1}=y_{t-1},
Y_{t_2}=y_{t-2})=g\left(\alpha^{1,1}+y_{t-1}\beta^{1,1}_1\right).
\]</span></p>
</div>
<div class="section level3">
<h3 id="beta-context-algorithm">Beta-Context algorithm<a class="anchor" aria-label="anchor" href="#beta-context-algorithm"></a>
</h3>
<p>Estimating a COVLMC model from two time series is more complex than
estimating a VLMC model. <code>mixvlmc</code> implements the
Beta-Context algorithm proposed in the original <a href="https://doi.org/10.1111/jtsa.12615" class="external-link">paper</a>. It is inspired from
the context algorithm used for VLMC (and proposed in <a href="https://dx.doi.org/10.1214/aos/1018031204" class="external-link">Variable length Markov
chains</a>). It can be summarized as follows:</p>
<ol style="list-style-type: decimal">
<li>the first step consists in building a context tree (see
<code><a href="../articles/context-trees.html">vignette("context-trees")</a></code>) from the <span class="math inline">\(\mathbf{X}\)</span> discrete sequences, almost
exactly as for a VLMC: the only difference is that to be kept in the
tree a context must appear a number of times that depends on its length,
on the dimension of the covariates and on the number of states. This
guarantees a minimal number of observations for the (maximum likelihood)
estimation of the context dependant multinomial logistic
regression.</li>
<li>the second step is an estimation one: a multinomial logistic
regression model is estimated for each context, using a number of past
values of <span class="math inline">\(\mathbf{Y}\)</span> equal to the
length of the context.</li>
<li>the rest of the algorithm consists in pruning the context tree and
the logistic models:
<ol style="list-style-type: decimal">
<li>leaf contexts are first assessed in terms of model simplification.
The likelihood-ratio test is used to decide whether the oldest value of
<span class="math inline">\(\mathbf{Y}\)</span> is relevant or not.
Essentially we compare e.g. <span class="math inline">\(g\left(\alpha^{1,1}+y_{t-1}\beta^{1,1}_1\right)\)</span>
to <span class="math inline">\(g\left(\alpha^{1,1}+y_{t-1}\beta^{1,1}_1+y_{t-2}\beta^{1,1}_2\right)\)</span>
as an estimator of <span class="math inline">\(\mathbb{P}(X_t=1\mid
X_{t-1}=1, X_{t-2}=1, Y_{t_1}=y_{t-1}, Y_{t_2}=y_{t-2})\)</span>;</li>
<li>based on the results of those tests, it may be possible to
completely remove a context from the tree, see the <a href="https://doi.org/10.1111/jtsa.12615" class="external-link">paper</a> for details.</li>
</ol>
</li>
</ol>
<p>This last pruning phase is carried out repeatedly as context removals
turn internal contexts into leaves that can then be further
simplified.</p>
</div>
</div>
<div class="section level2">
<h2 id="covlmc-in-practice">COVLMC in practice<a class="anchor" aria-label="anchor" href="#covlmc-in-practice"></a>
</h2>
<div class="section level3">
<h3 id="estimation">Estimation<a class="anchor" aria-label="anchor" href="#estimation"></a>
</h3>
<p>COVLMC estimation is provided by the <code><a href="../reference/covlmc.html">covlmc()</a></code> function.
We build first a simple example data set as follows:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">0</span><span class="op">)</span></span>
<span><span class="va">nb_obs</span> <span class="op">&lt;-</span> <span class="fl">200</span></span>
<span><span class="va">covariates</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="va">nb_obs</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fl">0</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">k</span> <span class="kw">in</span> <span class="fl">2</span><span class="op">:</span><span class="va">nb_obs</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="co">## we induce a simple dependency to the covariate</span></span>
<span>  <span class="co">## and an order 1 memory</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="va">covariates</span><span class="op">$</span><span class="va">y</span><span class="op">[</span><span class="va">k</span> <span class="op">-</span> <span class="fl">1</span><span class="op">]</span> <span class="op">&lt;</span> <span class="fl">0.5</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="kw">if</span> <span class="op">(</span><span class="va">x</span><span class="op">[</span><span class="va">k</span> <span class="op">-</span> <span class="fl">1</span><span class="op">]</span> <span class="op">==</span> <span class="fl">0</span><span class="op">)</span> <span class="op">{</span></span>
<span>      <span class="va">x</span><span class="op">[</span><span class="va">k</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>, <span class="fl">1</span>, prob <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.7</span>, <span class="fl">0.3</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="op">}</span> <span class="kw">else</span> <span class="op">{</span></span>
<span>      <span class="va">x</span><span class="op">[</span><span class="va">k</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>, <span class="fl">1</span>, prob <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.3</span>, <span class="fl">0.7</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="op">}</span></span>
<span>  <span class="op">}</span> <span class="kw">else</span> <span class="op">{</span></span>
<span>    <span class="kw">if</span> <span class="op">(</span><span class="va">x</span><span class="op">[</span><span class="va">k</span> <span class="op">-</span> <span class="fl">1</span><span class="op">]</span> <span class="op">==</span> <span class="fl">0</span><span class="op">)</span> <span class="op">{</span></span>
<span>      <span class="va">x</span><span class="op">[</span><span class="va">k</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>, <span class="fl">1</span>, prob <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.9</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="op">}</span> <span class="kw">else</span> <span class="op">{</span></span>
<span>      <span class="va">x</span><span class="op">[</span><span class="va">k</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>, <span class="fl">1</span>, prob <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.5</span>, <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="op">}</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>Then we estimate a COVLMC as follows:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/covlmc.html">covlmc</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">covariates</span><span class="op">)</span></span>
<span><span class="va">model</span></span>
<span><span class="co">#&gt; VLMC with covariate context tree on 0, 1 </span></span>
<span><span class="co">#&gt;  cutoff in quantile scale: 0.05</span></span>
<span><span class="co">#&gt;  Number of contexts: 2 </span></span>
<span><span class="co">#&gt;  Maximum context length: 1</span></span></code></pre></div>
<p>The estimation process is controlled by three parameters:</p>
<ul>
<li>
<code>max_depth</code>: the largest order/memory considered for the
COVLMC (defaults to 100). This parameter is essentially a computational
burden control parameter. It does not play a major role in COVLMC
estimation because of the constraints imposed by <code>min_size</code>.
The default value is very conservative;</li>
<li>
<code>min_size</code>: this parameter controls the minimal number of
occurrences needed for a context to be included in the initial context
tree. It gives the number of occurrences <em>per parameter</em> of the
logistic model which depends on both the length of the context, the
dimension of the covariates and the number of states;</li>
<li>
<code>alpha</code>: is the parameter of the pruning process of the
Beta-Context algorithm. Pruning decisions are all based on likelihood
ratio tests and <code>alpha</code> is the common level of all those
tests.</li>
</ul>
<p>The default parameters work well on the previous example, as shown by
the obtained model:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/draw.html">draw</a></span><span class="op">(</span><span class="va">model</span>, model <span class="op">=</span> <span class="st">"full"</span>, p_value <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="co">#&gt; *</span></span>
<span><span class="co">#&gt; +-- 0 ([ (I)    y_1  </span></span>
<span><span class="co">#&gt; |        -2.951 6.236 ])</span></span>
<span><span class="co">#&gt; '-- 1 ([ (I)   y_1   </span></span>
<span><span class="co">#&gt;          1.719 -1.881 ])</span></span></code></pre></div>
<p>The model has 2 contexts, 0 and 1, as expected. The logistic models
are described by their parameters. For context 0, the intercept is
negative and the coefficient of <span class="math inline">\(y_{t-1}\)</span> is positive: the probability of
switching to 1 is small when <span class="math inline">\(y_{t-1}\)</span> is small and increases with <span class="math inline">\(y_{t-1}\)</span>. For context 1, the situation is
reversed and the effect of <span class="math inline">\(y_{t-1}\)</span>
is smaller. This is consistent with the way the series were
constructed.</p>
<p>Notice however that obtained an interesting model with the default
parameters should not be seen as a general property and proper model
choice must be implemented.</p>
</div>
<div class="section level3">
<h3 id="model-choice">Model choice<a class="anchor" aria-label="anchor" href="#model-choice"></a>
</h3>
<p>As COVLMC estimation fits a potentially large number of logistic
models to the data, the use of a penalized likelihood approach is
recommended to set its parameters and avoid overfitting.</p>
<p>However, model choice is more complex in the case of the COVLMC than
for VLMC. In particular, the pair
<code><a href="../reference/cutoff.html">cutoff()</a></code>/<code><a href="../reference/prune.html">prune()</a></code> does not work as well for
COVLMC than for VLMC (see
<code><a href="../articles/variable-length-markov-chains.html">vignette("variable-length-markov-chains")</a></code>). Indeed the
pruning process of the Beta-Context algorithm is such that its effects
cannot be predicted as easily as the ones of the Context algorithm. In
practice, computing the largest <code>alpha</code> (test level) that is
guaranteed to make a minimal but actual pruning of a given COVLMC is
easy. But subsequent cut off values could be misleading. To avoid any
problem it is therefore recommended to rely on the
<code><a href="../reference/tune_covlmc.html">tune_covlmc()</a></code> function that has been designed to explore
the full “pruning space” associated to a given data set.</p>
<p>Used on the artificial example above, it gives:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model_tune</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/tune_covlmc.html">tune_covlmc</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">covariates</span><span class="op">)</span></span>
<span><span class="va">model_tune</span></span>
<span><span class="co">#&gt; VLMC with covariate context tree on 0, 1 </span></span>
<span><span class="co">#&gt;  cutoff in quantile scale: 0.1236</span></span>
<span><span class="co">#&gt;  Number of contexts: 2 </span></span>
<span><span class="co">#&gt;  Maximum context length: 1 </span></span>
<span><span class="co">#&gt;  Selected by BIC (245.1046) with likelihood function "truncated" (-112.3135)</span></span></code></pre></div>
<p>and</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/draw.html">draw</a></span><span class="op">(</span><span class="fu"><a href="../reference/as_covlmc.html">as_covlmc</a></span><span class="op">(</span><span class="va">model_tune</span><span class="op">)</span>, model <span class="op">=</span> <span class="st">"full"</span>, p_value <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="co">#&gt; *</span></span>
<span><span class="co">#&gt; +-- 0 ([ (I)    y_1  </span></span>
<span><span class="co">#&gt; |        -2.951 6.236 ])</span></span>
<span><span class="co">#&gt; '-- 1 ([ (I)   y_1   </span></span>
<span><span class="co">#&gt;          1.719 -1.881 ])</span></span></code></pre></div>
<p>The resulting model is the same as the one obtained before but it was
properly obtained by minimising the BIC.</p>
<p>As for <code><a href="../reference/tune_vlmc.html">tune_vlmc()</a></code>, the <code>max_depth</code> parameter
is automatically increased to avoid using it inadvertently as a
regularisation parameter. However, while <code>min_size</code> is
generally considered as not having a major influence on the model
selection for VLMC, this is not the case for COVLMC. There is currently
no support in <code>mixvlmc</code> for an automatic choice of
<code>min_size</code> and one should therefore test several values and
compare the obtained BIC/AIC. In the articial case, we can try for
instance <code>min_size=2</code> as follows:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model_tune_2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/tune_covlmc.html">tune_covlmc</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">covariates</span>, min_size <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">model_tune_2</span></span>
<span><span class="co">#&gt; VLMC with covariate context tree on 0, 1 </span></span>
<span><span class="co">#&gt;  cutoff in quantile scale: 0.01195</span></span>
<span><span class="co">#&gt;  Number of contexts: 2 </span></span>
<span><span class="co">#&gt;  Maximum context length: 1 </span></span>
<span><span class="co">#&gt;  Selected by BIC (242.3184) with likelihood function "truncated" (-112.3135)</span></span></code></pre></div>
<p>and <code>min_size=10</code> as follows:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model_tune_10</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/tune_covlmc.html">tune_covlmc</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">covariates</span>, min_size <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="va">model_tune_10</span></span>
<span><span class="co">#&gt; VLMC with covariate context tree on 0, 1 </span></span>
<span><span class="co">#&gt;  cutoff in quantile scale: 0.1236</span></span>
<span><span class="co">#&gt;  Number of contexts: 2 </span></span>
<span><span class="co">#&gt;  Maximum context length: 1 </span></span>
<span><span class="co">#&gt;  Selected by BIC (245.6423) with likelihood function "truncated" (-112.3135)</span></span></code></pre></div>
<p>Here we see no particular effect of the parameter because of the
simplicity of the problem.</p>
<p>Let us now come back to the electricity consumption example described
above. We introduce a very basic day/night covariate as follows:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">elec_cov</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>day <span class="op">=</span> <span class="op">(</span><span class="va">pc_week_15_16</span><span class="op">$</span><span class="va">hour</span> <span class="op">&gt;=</span> <span class="fl">7</span> <span class="op">&amp;</span> <span class="va">pc_week_15_16</span><span class="op">$</span><span class="va">hour</span> <span class="op">&lt;=</span> <span class="fl">18</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>and fit a COVLMC with</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">elec_tune</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/tune_covlmc.html">tune_covlmc</a></span><span class="op">(</span><span class="va">elec_dts</span>, <span class="va">elec_cov</span><span class="op">)</span></span>
<span><span class="va">elec_tune</span></span>
<span><span class="co">#&gt; VLMC with covariate context tree on low, typical, high </span></span>
<span><span class="co">#&gt;  cutoff in quantile scale: 0.007218</span></span>
<span><span class="co">#&gt;  Number of contexts: 7 </span></span>
<span><span class="co">#&gt;  Maximum context length: 3 </span></span>
<span><span class="co">#&gt;  Selected by BIC (2243.59) with likelihood function "truncated" (-1064.74)</span></span></code></pre></div>
<p>The model selection process can be represented graphically as
follows:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">elec_tune</span><span class="op">$</span><span class="va">results</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">alpha</span>, y <span class="op">=</span> <span class="va">BIC</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html" class="external-link">geom_line</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html" class="external-link">geom_point</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p><img src="covlmc_files/figure-html/unnamed-chunk-13-1.png" width="672" style="display: block; margin: auto;">
or automatically using e.g. <code><a href="https://ggplot2.tidyverse.org/reference/autoplot.html" class="external-link">autoplot()</a></code> as follows:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html" class="external-link">autoplot</a></span><span class="op">(</span><span class="va">elec_tune</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="covlmc_files/figure-html/unnamed-chunk-14-1.png" width="672" style="display: block; margin: auto;"></p>
<p>The final model is:</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/draw.html">draw</a></span><span class="op">(</span><span class="fu"><a href="../reference/as_covlmc.html">as_covlmc</a></span><span class="op">(</span><span class="va">elec_tune</span><span class="op">)</span>, model <span class="op">=</span> <span class="st">"full"</span>, p_value <span class="op">=</span> <span class="cn">FALSE</span>, with_state <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; *</span></span>
<span><span class="co">#&gt; +-- low ([ (low)   | (I)   </span></span>
<span><span class="co">#&gt; |          typical | -1.491</span></span>
<span><span class="co">#&gt; |          high    | -4.487 ])</span></span>
<span><span class="co">#&gt; '-- typical</span></span>
<span><span class="co">#&gt; |   +-- low ([ (low)   | (I)   </span></span>
<span><span class="co">#&gt; |   |          typical | 0.4643</span></span>
<span><span class="co">#&gt; |   |          high    | -1.992 ])</span></span>
<span><span class="co">#&gt; |   '-- typical</span></span>
<span><span class="co">#&gt; |   |   +-- low ([ (low)   | (I)   </span></span>
<span><span class="co">#&gt; |   |   |          typical | 0.3054</span></span>
<span><span class="co">#&gt; |   |   |          high    | -2.234 ])</span></span>
<span><span class="co">#&gt; |   |   '-- typical ([ (low)   | (I)     day_1TRUE</span></span>
<span><span class="co">#&gt; |   |   |              typical | 1.839   0.975    </span></span>
<span><span class="co">#&gt; |   |   |              high    | -0.1823 -0.1462   ])</span></span>
<span><span class="co">#&gt; |   |   '-- high ([ (low)   | (I)   </span></span>
<span><span class="co">#&gt; |   |               typical | 2.773 </span></span>
<span><span class="co">#&gt; |   |               high    | 0.8473 ])</span></span>
<span><span class="co">#&gt; |   '-- high ([ (low)   | (I)  </span></span>
<span><span class="co">#&gt; |               typical | 3.367</span></span>
<span><span class="co">#&gt; |               high    | 1.705 ])</span></span>
<span><span class="co">#&gt; '-- high ([ (typical) | (I)  </span></span>
<span><span class="co">#&gt;             high      | 1.474 ])</span></span></code></pre></div>
<p>It shows some interesting patterns:</p>
<ul>
<li>one of the logistic model is degenerate: in the <code>high</code>
context, no transition to a <code>low</code> context can happen. This
was already observed with the VLMC;</li>
<li>the only dependency with respect to the covariate is in the context
typical, typical, typical. In this case, the probability to stay in the
typical context is increased during day time and decreased (but to a
lesser extent) during the night. In practice, this means that the model
is able to generate longer sequences that stay in the typical state
during the day than at night.</li>
</ul>
<p>Notice finally that for this real world example, the
<code>min_size</code> parameter has some influence on the results.
Setting it to a smaller value does not change the final model, as shown
below:</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">elec_tune_3</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/tune_covlmc.html">tune_covlmc</a></span><span class="op">(</span><span class="va">elec_dts</span>, <span class="va">elec_cov</span>, min_size <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="va">elec_tune_3</span></span>
<span><span class="co">#&gt; VLMC with covariate context tree on low, typical, high </span></span>
<span><span class="co">#&gt;  cutoff in quantile scale: 0.007218</span></span>
<span><span class="co">#&gt;  Number of contexts: 7 </span></span>
<span><span class="co">#&gt;  Maximum context length: 3 </span></span>
<span><span class="co">#&gt;  Selected by BIC (2239.393) with likelihood function "truncated" (-1064.74)</span></span></code></pre></div>
<p>However, increasing the parameter to, e.g., 10 generates a simpler
but weaker model as show here:</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">elec_tune_10</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/tune_covlmc.html">tune_covlmc</a></span><span class="op">(</span><span class="va">elec_dts</span>, <span class="va">elec_cov</span>, min_size <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="va">elec_tune_10</span></span>
<span><span class="co">#&gt; VLMC with covariate context tree on low, typical, high </span></span>
<span><span class="co">#&gt;  cutoff in quantile scale: 0.03454</span></span>
<span><span class="co">#&gt;  Number of contexts: 5 </span></span>
<span><span class="co">#&gt;  Maximum context length: 2 </span></span>
<span><span class="co">#&gt;  Selected by BIC (2260.505) with likelihood function "truncated" (-1088.409)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="diagnostics">Diagnostics<a class="anchor" aria-label="anchor" href="#diagnostics"></a>
</h3>
<p>The package provides numerous ways to analyse a COVLMC. asic
functions include</p>
<ul>
<li>
<code><a href="../reference/states.html">states()</a></code> returns the state space of the model;</li>
<li>
<code><a href="../reference/depth.html">depth()</a></code> returns the length of the longest context in
the model;</li>
<li>
<code><a href="../reference/covariate_depth.html">covariate_depth()</a></code> returns the longest memory used by
the model with respect to covariates;</li>
<li>
<code><a href="../reference/context_number.html">context_number()</a></code> returns the number of contexts in the
model.</li>
</ul>
<p>For instance, the large model obtained above has the following
characteristics:</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">elec_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/as_covlmc.html">as_covlmc</a></span><span class="op">(</span><span class="va">elec_tune</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/states.html">states</a></span><span class="op">(</span><span class="va">elec_model</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] low     typical high   </span></span>
<span><span class="co">#&gt; Levels: low typical high</span></span>
<span><span class="fu"><a href="../reference/depth.html">depth</a></span><span class="op">(</span><span class="va">elec_model</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 3</span></span>
<span><span class="fu"><a href="../reference/covariate_depth.html">covariate_depth</a></span><span class="op">(</span><span class="va">elec_model</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 1</span></span>
<span><span class="fu"><a href="../reference/context_number.html">context_number</a></span><span class="op">(</span><span class="va">elec_model</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 7</span></span></code></pre></div>
<p>VLMC objects support classical statistical functions such as:</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/logLik.html" class="external-link">logLik</a></span><span class="op">(</span><span class="va">elec_model</span><span class="op">)</span></span>
<span><span class="co">#&gt; 'log Lik.' -1064.74 (df=15)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/AIC.html" class="external-link">AIC</a></span><span class="op">(</span><span class="va">elec_model</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 2159.48</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/AIC.html" class="external-link">BIC</a></span><span class="op">(</span><span class="va">elec_model</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 2243.59</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="contexts">Contexts<a class="anchor" aria-label="anchor" href="#contexts"></a>
</h3>
<p>The model can be explored in details by drawing its context tree (see
<code><a href="../articles/context-trees.html">vignette("context-trees")</a></code> for details) as follows:</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/draw.html">draw</a></span><span class="op">(</span><span class="va">elec_model</span><span class="op">)</span></span>
<span><span class="co">#&gt; * (merging (low and high): 8.121e-230)</span></span>
<span><span class="co">#&gt; +-- low (0.03454 [ -1.491</span></span>
<span><span class="co">#&gt; |                  -4.487 ])</span></span>
<span><span class="co">#&gt; '-- typical (merging (low and high): 8.264e-09)</span></span>
<span><span class="co">#&gt; |   +-- low (0.8447 [ 0.4643</span></span>
<span><span class="co">#&gt; |   |                 -1.992 ])</span></span>
<span><span class="co">#&gt; |   '-- typical (collapsing: 3.961e-10)</span></span>
<span><span class="co">#&gt; |   |   +-- low (0.2323 [ 0.3054</span></span>
<span><span class="co">#&gt; |   |   |                 -2.234 ])</span></span>
<span><span class="co">#&gt; |   |   '-- typical (6.269e-05 [ 1.839   0.975  </span></span>
<span><span class="co">#&gt; |   |   |                        -0.1823 -0.1462 ])</span></span>
<span><span class="co">#&gt; |   |   '-- high (0.6393 [ 2.773 </span></span>
<span><span class="co">#&gt; |   |                      0.8473 ])</span></span>
<span><span class="co">#&gt; |   '-- high (0.1638 [ 3.367</span></span>
<span><span class="co">#&gt; |                      1.705 ])</span></span>
<span><span class="co">#&gt; '-- high (0.776 [ 1.474 ])</span></span></code></pre></div>
<p>The <code><a href="../reference/draw.covlmc.html">draw.covlmc()</a></code> function is more advanced than its
VLMC counterpart. It provides more detailed information, particularly
regarding p-values associated with pruning operations. The “merging”
p-value corresponds to replacing some of the contexts with a single
joint model, while the “collapsing” p-value is associated to pruning all
the sub-contexts of a context. P-values associated to specific models
correspond to reducing the memory of the corresponding model, that is
discarding the dependency of the conditional probability towards the
oldest covariates.</p>
<p>To explore the contexts in a programmatically way, one should rely on
the <code><a href="../reference/contexts.html">contexts()</a></code> function. COVLMC contexts have additional
characteristics compared to VLMC and context trees. In particular, the
<code><a href="../reference/contexts.html">contexts()</a></code> function can report the model associated to each
context, either by its parameters only:</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/contexts.html">contexts</a></span><span class="op">(</span><span class="va">elec_model</span>, model <span class="op">=</span> <span class="st">"coef"</span><span class="op">)</span></span>
<span><span class="co">#&gt;        context         coef</span></span>
<span><span class="co">#&gt; 1          low -1.49102....</span></span>
<span><span class="co">#&gt; 2 typical, low 0.464305....</span></span>
<span><span class="co">#&gt; 3 typical,.... 0.305381....</span></span>
<span><span class="co">#&gt; 4 typical,.... 1.839226....</span></span>
<span><span class="co">#&gt; 5 typical,.... 2.772588....</span></span>
<span><span class="co">#&gt; 6 typical,.... 3.367295....</span></span>
<span><span class="co">#&gt; 7         high 1.473892....</span></span></code></pre></div>
<p>or using the models themselves:</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/contexts.html">contexts</a></span><span class="op">(</span><span class="va">elec_model</span>, model <span class="op">=</span> <span class="st">"full"</span><span class="op">)</span></span>
<span><span class="co">#&gt;        context                                            model</span></span>
<span><span class="co">#&gt; 1          low &lt;S4 class 'vglm' [package "VGAM"] with 37 slots&gt;</span></span>
<span><span class="co">#&gt; 2 typical, low &lt;S4 class 'vglm' [package "VGAM"] with 37 slots&gt;</span></span>
<span><span class="co">#&gt; 3 typical,.... &lt;S4 class 'vglm' [package "VGAM"] with 37 slots&gt;</span></span>
<span><span class="co">#&gt; 4 typical,.... &lt;S4 class 'vglm' [package "VGAM"] with 37 slots&gt;</span></span>
<span><span class="co">#&gt; 5 typical,.... &lt;S4 class 'vglm' [package "VGAM"] with 37 slots&gt;</span></span>
<span><span class="co">#&gt; 6 typical,.... &lt;S4 class 'vglm' [package "VGAM"] with 37 slots&gt;</span></span>
<span><span class="co">#&gt; 7         high &lt;S4 class 'vglm' [package "VGAM"] with 37 slots&gt;</span></span></code></pre></div>
<p>See <code><a href="../reference/contexts.covlmc.html">contexts.covlmc()</a></code> for details.</p>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by <a href="https://fabrice-rossi.github.io/" class="external-link">Fabrice Rossi</a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
